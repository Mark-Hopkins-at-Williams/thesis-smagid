\chapter{Conclusion}
\label{chap:conclusion}

In this thesis, we have detailed our research into the potential use of autoencoder-like neural networks to encode typeface style. The most common font selection tools largely ignore style as an aspect of typeface selection, making it difficult or impossible to ask questions like ``Which fonts are most similar to Futura?'' or ``What is a font which is similar to Times New Roman but more playful?'' The first half of our research involved gathering a large dataset of font character data representative of a wide range of typeface styles, including character sets from 14,391 typefaces across the Google Fonts and Apple libraries and the Capitals64 dataset (see Section \ref{data-collection}), and training several models based on the original autoencoder model to encode typeface style vectors of input character sets. The second half of this project involved building a useful proof-of-concept user tool on these typeface style encoding data, in order to demonstrate our hypothesis that the style encodings generated by these autoencoder-based neural networks can serve as a useful foundation for style-based font selection. Finally, we quantitatively evaluated the stylistic encoding space produced by our models, and additionally performed a small user study to both quantitatively and qualitatively evaluate the performance of our font selection tool.

\section{Findings}

We find that many of our models succeed in encoding certain aspects of typeface style, but our model adapted from Srivatsan et al.\ \cite{srivatsan2020} and trained on our larger dataset---including the fonts from Google Fonts, Apple, and Capitals64---performed the strongest when evaluated against the novel font attribute categories created by the Google Fonts library: when looking at Euclidean distance as a metric of style vector similarity, all but one of the Google Fonts style categories corresponded to a closer-than-average Euclidean similarity score. The other models captured fewer of these categories, and we generally find that models which were more complex and disentangled character structure (A or B, e.g.) from style (determined by typeface) performed better on these Euclidean similarity metrics. In general, ``easier'' style categories---such as serif and sans-serif category groups---were more likely to have a closer-than-average similarity score across the models, while more abstract and stylistically-diverse categories like feeling-loud or seasonal-kwanzaa were less likely to have closer-than-average distance scores. We also measured these similarity scores using cosine similarity distances, and found that the cosine similarity metric told a somewhat different story than Euclidean distance similarity---the models which performed better under Euclidean distance similarity tended to perform poorer under cosine similarity, and vise-versa---but because our font selection tool was built around Euclidean distance similarity, we determine that these differing cosine similarity results are not especially important for the purpose of this work.

We additionally evaluated our font selection interface with a small user study, in which we tasked users to match fonts using three different font selectors: a basic alphabetical list, the Google Fonts category-based selection interface, and our style-encoding based tool. Because of our study's small size---only 12 participants---and the high amount of noise in our experiments, we were not able to draw conclusions from our data about user accuracy or performance between the three interfaces. In the qualitative portion of our study, we found that users enjoyed the novel selection interface, its exploratory nature, and the ability to narrow down typeface search based on style; however, many users reported finding the tool confusing or unintuitive at first and wished the tool included certain features---such as name-based search and the ability to preview text in a typeface, rather than selecting an individual character to display---to improve the search experience.

\section{Future Work}

There are many aspects of this research which could be improved upon or investigated further. This section details those areas of future work, split into two overall categories: model-based improvements, and interface-based improvements. Overall, there is significant potential for further research around inference-based font selection interfaces---especially until better font selection tools are developed and introduced into mainstream word processing and graphic design software.

\subsection{Model Improvements}

There is a large diversity of approaches to building neural image models; for that reason, much time could be spent implementing different models and comparing their performance for the typeface style encoding task. The scope of this thesis research allowed only enough time to implement and evaluate a few models (Basic Autoencoder, Style Transfer, and the Srivatsan model), but it would be interesting and fruitful to explore a wider range of model approaches. However, I believe there is great potential for style encoding models based not on bitmap pixel images, but rather on vector graphics---which encode geometric shapes instead of pixel values. In fact, this is the native representation of font files---which ensures that fonts can be viewed clearly and without pixelation at any scale---and building font reconstruction and style encoding models based on these non-pixel representations could potentially yield more effective style representations. This would also yield much cleaner reconstructed fonts---whose representation would conveniently match the native font representation---making generative tasks (i.e.\ creating \textit{new} fonts based on existing data) much more realistic. Currently, the font images generated by bitmap-based models look (at best) fuzzy and pixelated, far from an actual useable font. Certain groups such as Carlier et al.\ \cite{carlier2020} have already begun to explore these directions in font generation, but certainly much more work can be done to explore this area of font style encoding and generation.

\subsection{Interface Improvements}

It is fair to say that our final font selection interface, while user friendly in certain ways, provides users with a bit too much control over the model space. Additionally, users reported the dimension-based selection interface to be somewhat confusing. While this is okay for our proof-of-concept---in order to demonstrate our hypothesis that these model style encodings could be used to create a useful style-based font selection tool---there is certainly a lot of room for improvement in the tool's interface. Future work, especially if this interface were to be built into a production-grade tool, would likely involve simplifying the interface, to limit user control and make the tool more approachable. Additionally, while our current implementation only includes typefaces from the Google Fonts library for the purposes of simplification, it would certainly be possible to support a wider range of fonts; however, it would probably be necessary to adapt the interface to use SVG character files rather than loading whole font files. Under the current implementation of loading those entire font files, the webapp interface would likely become unusably slow given enough fonts.

\section{Lessons Learned}

The process of this thesis research, spanning eight months of my undergraduate career, has been a significant undertaking. I have grown as a programmer, a researcher, and a student. Looking back, there are some things I would have done differently. For one, I was less diligent than I would have liked with the organization of my code. In my thesis directory there exist over 130 Python and Bash scripts written for small and large tasks; many of these could have been combined and condensed. Additionally, I did not initially document these scripts as well as I could have. However, if you are reading this, my final project repository includes all of the important scripts needed to reproduce this project, and in those files I have attempted to make my work as clear and well-documented as possible. You can find these files at the link referenced below.\footnote{\url{https://github.com/Mark-Hopkins-at-Williams/thesis-smagid}}

I have learned that research---especially with good advisors, family, and friends supporting you---is an incredibly rewarding process. It is an experience which teaches you much more about yourself, your approaches to work, your motivation and gumption, and how to commit to an endeavor to the very end. For this experience, I am incredibly grateful to all those aforementioned people who have helped me in working towards this final product. I hope that this project has been as enjoyable to read about as it has been for me to code and write; that it might inspire or motivate someone else in their research journey; and, perhaps, that it might even contribute to some future research in the field. For now, I will wrap up the final edits on this draft, and soon take a very, very long nap.